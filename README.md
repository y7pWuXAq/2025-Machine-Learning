# 2025-Machine-Learning
2025년 빅데이터 기반 AI 개발 전문가 과정 머신러닝 기본 학습 리포지토리
<br>



### DAY 01
- 머신러닝 맛보기 (K-최근접이웃 모델)
    - 머신러닝 최초 가장 기본으로 사용하기 좋음 (실전에는 사용안하는 추세, 너무 기본 모델)

- 기본 라이브러리 설치
 - plotly : 시각화
```
pip install ipython jupyter pandas xlrd seaborn pyarrow openpyxl selenium folium plotly

pip install matplotlib==3.8
pip install numpy==1.26
```

- 머신러닝 라이브러리 설치
```
pip install scikit-learn==1.5.0
pip install xgboost==2.0.2
```
- 라이브러리 정의
```py
from sklearn.neighbors import KNeighborsClassifier
```
- <산점도의 형태에 따라서 분석 방법 선택>
- 선형(직선 또는 곡선 포함) 형태인 경우
    - 일반적으로 회귀분석 방법을 사용(분류 분석도 가능)
    - 선형이면서 연속적 값을 예측하는 경우에는 --> 회귀분석 모델 사용
    - 선형이면서 판단을 하는 경우 -> 분류분석 모델 사용
    - 선형이면서 판단을 하는 경우에는 분류 기준이 되는 범주형 데이터가 포함되어 있어야 함
- 선형 형태가 아닌 경우
    - 분류 분석 방법 중 -> 분류분석 모델 또는 군집분석 모델을 사용
<br>

- <분석 방법>
- 1. 회귀분석
    - 지도학습 회귀분석모델 사용 : 정답을 알고 있는 경우 사용
    - 정답의 형태 : 연속형 데이터
    - 예측의 의미 : 정답을 예측하는 것으로, 연속형 데이터를 추정하는 것
- 2. 분류분석
    - 2-1. 분류분석
        - 지도학습 분류분석모델 사용 : 정답을 알고 있는 경우 사용
        - 정답의 형태 : 범주형 데이터
        - 판단(분류)의 의미 : 정답을 판단하는 것으로 범주형 데이터를 분류하는 것
    - 2-1. 군집분석
        - 비지도 학습 군집분석모델 사용 : 정답을 모르는 상태에서 사용
        - 군집의 의미 : 데이터의 임의 특성을 기준으로 군집(클러스트, 그룹)을 만드는 것
            - 어느 그룹에 속하는지를 판단하는 것 (범주형 데이터를 분류하는 의미)
<br>

- 분류를 위한 데이터 전처리 및 가공
- 1. 데이터 특성에 맞게 합치기
    - 훈련(학습)을 시키기 위한 데이터 형태로 만들기
        - 문제 데이터 : [ [길이, 무게], [길이, 무게] ... ]
            - 문제 데이터를 [독립변수, X] 라고 칭함
            - 독립변수(x)는 2차원 형태를 갖추어야 함
            - 머신러닝 필수사항

        - 정답 데이터 : [ 도미, 도미, 도미, .... 빙어, 빙어 ... ]
            - 정답 데이터를 [종속변수, y] 라고 칭함
            - 종속변수(y)는 1차원 형태를 갖추어야 함
            - 머신러닝 & 딥러닝 필수사항
            - 분류 기준에서의 종속변수 형태
                - 둘중 하나를 분류할 때 > "이진분류" 0 또는 1중에 분류
                - 세개 이상 중에 하나를 분류할 때 > "다중분류" 0, 1, 2 ... n 중에 분류

    - 훈련(학습)에 사용되는 모든 특성의 데이터는 숫자값을 사용
        - 범주형 데이터가 문자인 경우에는 숫자(0~n까지)로 사용
        - 이때 원-핫인코딩을 이용하는 경우도 있음
        - 주로 직접 숫자로 변환하는 코드를 작성하여 변환

    - 분석 용어
        - 각 데이터(도미, 빙어)를 "특성" 이라고 칭함
        - 특성 => 컬럼, 항목, 퓨처(딥러닝), ... 모두 같은 의미
<br>

- 훈련(학습) 시키기
- 훈련에 사용할 훈련(학습) 모델
    - 모델 라이브러리 : KNeighborsClassifier
    - 모델 패키지 : sklearn.neighbors
    - 모델 이름 : KNN (K-Nearest Neighbors : K-최근접 이웃 "알고리즘"을 사용하는 "모델")
    - KNN은 머신러닝 모델 중에 가장 간단한 모델
    - 타 모델들과 비교용으로 주로 사용됨
<br>

- 처리 방식
    - 분류(판단, 예측) 하고자 하는 특성값들과 가장 가까운 이웃의 값들과 거리 비교
    - 가장 가까운 곳의 갯수(이웃들의 갯수)를 기준으로 비율(확률) 대비 판단
    - 비율이 가장 높은 쪽으로 판단 (다수결의 원칙을 따름)
<br>

- 훈련(학습) 순서
    - 1. 데이터 수집
    - 2. 데이터 전처라
    - 3. 데이터 가공
        - 독립변수, 종속변수 생성
        - 훈련 데이터, 테스트 데이터로 분류 또는 훈련, 검증, 테스트 데이터로 분류
    - 4. 훈련모델 생성
    - 5. 훈련 시키기
        - 훈련 데이터 사용
    - 6. 훈련모델 정확도 검증
        - 테스트 데이터 사용 또는 검증 데이터 사용
        - 훈련 정확도 및 테스트(검증) 정확도 확인 후 비교
        - 6-1. 튜닝
        - 6-2. 성능평가
    - 7. 예측하기(임의 데이터로 정답 잘 맞추는지 검증)
        - 임의 데이터, 즉 테스트 데이터를 의미
        - 7-1. 최종 정확도 검증(테스트 정확도 검증)
        - 7-2. 성능평가
<br>

- 하이퍼 파라미터 사용하기
    - 하이퍼 파라미터 의미
        - 사람이 직접 성능을 높이기 위해 특정 파라미터의 값을 수정해 주어야하는 것을 의미
        - 훈련 모델의 성능(정확도)에 영향을 미치는 파라미터를 "하이퍼 파라미터"라고 칭함
        - 하이퍼 파라미터의 값을 변경(튜닝)하면서 성능을 향상 시킬 수 있음

    - 하이퍼 파라미터 튜닝
        - 성능을 높이기 위해 파라미터의 값을 바꿔가면서 훈련검증을 하는 방식을 의미

    - KNN 에서 사용하는 하이퍼 파라미터
        - n_neighbors : 이웃의 갯수를 변경하면서 성능을 개선할 수 있음 (기본값 = 5)
        - 모델 생성시에 속성으로 넣어줌
        
- [K-최근접이웃 예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day01/01_K-최근접이웃_모델_생선구분.ipynb)
<br><br>



### DAY02

- 데이터 분리 : 훈련, 테스트 (또는 훈련, 검증, 테스트)

- 데이터 분리
    - 훈련 데이터 : fit()
    - 검증 데이터 : score()
    - 테스트 데이터 : predict()
    - 훈련과 테스트 데이터로만 분리한 경우에는 테스트 데이터로 score() 및 predict() 모두 사용
<br>

- 데이터를 분리하는 이유
    - 훈련이 잘 되었는지에 대한 모델의 성능 검증을 위함
    - 검증에 타당성을 입증하기 위함
<br>

- 분리기준
    - 2개로 분리 -> 훈련 : 테스트
    - 3개로 분리 -> 훈련 : 검증 : 테스트
<br>

- 분리 비율
    - 2개로 분리
        - 훈련(7) : 테스트(3) : 주로 사용 됨
        - 훈련(7.5) : 테스트 (2.5)
        - 훈련(6) : 테스트(4)
    - 3개로 분리
        - 훈련(6) : 검증(2) : 테스트(2) : 주로 사용 됨
        - 훈련(7) : 검증(1.5) : 테스트(1.5)
        - 훈련(7) : 검증(2) : 테스트(1)
<br>

- 주로 사용되는 변수 이름
    - 훈련 데이터(train)
        - 훈련 독립변수명 : train_input, train_X, train_data
        - 훈련 종속변수명 : train_target, train_y
    - 검증 데이터(val)
        - 훈련 독립변수명 : val_input, val_X, val_data
        - 훈련 종속변수명 : val_target, val_y
    - 테스트 데이터(test)
        - 훈련 독립변수명 : test_input, test_X, test_data
        - 훈련 종속변수명 : test_target, test_y
<br>

- 편향 해소 방법
    - 데이터의 특정 값들이 골고루 잘 섞이게 하면 됨
    - 데이터 전처리 및 가공 단계에서 처리
    - 섞는다는 의미 "split" 이라고 함
    <br>
    ```py
    plt.title("훈련도 데이터와 산점도 데이터 시각화")
    plt.scatter(train_input[ : ,0], train_input[: , 1], color="yellowgreen", label ="훈련 데이터")
    plt.scatter(test_input[ : ,0], test_input[ : ,1], color="skyblue", label ="테스트 데이터")
    plt.xlabel("length")
    plt.ylabel("weight")
    plt.legend()
    plt.grid()
    plt.show()
    ```
    <br>
    ![편향해소데이터섞기](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/images/d01_편향해소랜덤섞기.png)

    - [KNN_훈련_및_테스트_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/01_KNN_훈련_및_테스트_데이터구성하기.ipynb)

    - [KNN_자동분류섞기_및_정규화_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/02_KNN_자동분류섞기_및_정규화.ipynb)
<br>

- KNN 회귀 모델
- 회귀모델의 결정계수(정확도)
    - 회귀모델에서는 정확도라고 표현하지 않으며, "결정계수"라고 함
    - 결정계수의 다른 표현 : 결정력, 설명력 이라고 함
    - 결정계수 값의 범위 : 0 ~ 1 사이의 값 (1에 가까울 수록 좋음)
    - 결과 문서 작성시 
        - "훈련의 결정계수가 0.97로 설명력이 매우 좋은 모델로 판단됨" 이라고 작성함
- 모델이 좋다 나쁘다의 판단 기준 값으로 사용
- +- 0.03 정도의 오차가 있는 모델이라고 표현
- [KNN_회귀모델_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/03_KNN_회귀모델.ipynb)
<br><br>



### DAY03

- 정확도를 이용하여 모델 성능 평가하기 : 과적합여부 판정
<br>

- 회귀분석 및 분류분석 모두 공통 적용되는 사항
    - 훈련 이후 훈련 데이터를 이용한 정확도(socre)와 검증(테스트) 데이터를 이용한 정확도(score) 비교
    - 비교한 결과를 기준으로 많은 차이가 나는 경우 -> "과적합이 발생한다" 라고 함
    - 과적합 용어 : 과대적합, 과소적합, 일반화
    - 과적합의 기준 : 정확한 정답은 없음(보통 0.1 차이가 나면 과적합이 발생한 것으로 봄)
<br>

##### 과적합 분류
- 과대적합
    - 훈련 정확도 > 검증 (또는 테스트) 정확도인 경우
    - 훈련 정확도가 1이 나온 경우 : 모델 사용 불가
    - 훈련 정확도와 검증(또는 테스트) 정확도가 0.1 이상 차이가 나는 경우
    - 과대적합 처리 방법
        - 1. 데이터 양 늘리기 (데이터 추가 수집 필요) -> 데이터 수집에 어려움이 있음
        - 2. 하이퍼 파라미터 튜닝 -> 일반적으로 선행해서 처리 시작
        - 3. 다른 모델 찾기 -> 1, 2 번으로 처리가 안될 경우 사용
    - 과소적합
        - 훈련 정확도 < 검증 (또는 테스트) 정확도인 경우
        - 훈련 모델 사용 불가
        - 과소적합 처리 방법
            - 1. 데이터 양 늘리기 (데이터 추가 수집 필요) -> 데이터 수집에 어려움이 있음
            - 2. 하이퍼 파라미터 튜닝 -> 일반적으로 선행해서 처리 시작
            - 3. 다른 모델 찾기 -> 1, 2 번으로 처리가 안될 경우 사용
    - 일반화
        - 훈련 정확도와 검증 (또는 테스트) 정확도 차이가 0.01 ~ 0.09 이내인 경우
<br>

- 문서에 표현하는 용어
    - 일반화가 되었다는 가정하에 주로 사용
    - 훈련 정확도(score) 0.95 이상 : 매우 훌륭한 모델
    - 훈련 정확도(score) 0.90 이상 : 훌륭한 모델
    - 훈련 정확도(score) 0.85 이상 : 좋은 모델
    - 훈련 정확도(score) 0.85 미만 : 좋다라는 표현은 사용하지 않음

- 가장 이상적인 정확도(score) 비교
    - 훈련 정확도 > 검증 정확도 > 테스트 정확도 : 가장 이상적
    - 훈련정확도 > 검증 정확도 < 테스트 정확도 : 이렇게 나오는 경우도 인정

- 가장 이상적인 정확도를 만들기 위한 작업들
    - 전처리 : 편향 처리, 적절한 데이터 분리, 스케일링
    - 하이퍼 파라미터 튜닝 : 모델마다 가지고 있는 성능에 영향을 미치는 파라미터 값 수정
    - 데이터 수집 : 양적 수집
<br>

##### 하이퍼 파라미터 튜닝
- 모델마다 튜닝할 파라미터는 각기 다름
- KNN 에서 기본적으로 튜닝할 파라미터 : 이웃의 갯수
- 튜닝방법
    1. 훈련모델 생성
     2. 최초 훈련 시키기
     3. 하이퍼 파라미터 값 변경 > 훈련 시키기
     4. 정확도 확인
     5. 3번 ~ 4번 반복

- 이웃의 갯수 3 ~ 훈련 데이터의 갯수만큼 훈련 시킨 결과
    - 훈련 정확도와 테스트 정확도를 선그래프 시각적으로 확인
    - x축 : 이웃의 갯수, y축 : 훈련 및 테스트 정확도
    - 훈련 정확도 선과 테스트 정확도 선을 하나의 그래프에 그려서 비교
    <br>
    ![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_이웃갯수에따른데이터정확도비교.png)

##### 최종 평가하기

- 회귀분석 평가
    - 평가를 위해서는 예측(predict)이 선행 되어야 함
    - 예측된 결과를 기준으로 평가를 수행

- 회귀분석 평가 방법
    - 평균절대오차(MAE, Mean Absolute Error)
    - 평균제곱오차(MSE, Mean Squere Error)
    - 결정계수(R2-score) == score()와 동일

- 평과 결과 해석
    - 평균절대오차(MAE)의 결과를 이용해서 오차의 범위 확인 가능
    - 결정계수(R2) 값을 이용하여 모델 선정여부 판정
        - 여러 모델들간에 비교하여 최종 선정 시에 R2-score의 값을 기준으로 선정여부 판정
        - 여러 모델 선정 기준 : R2-score 값이 높고 훈련 정확도가 높은 모델 선정
<br>

##### KNN 모델의 한계를 극복한 모델들 (회귀 및 분류 공통)
- ** 지도학습 기반에서 회귀 및 분류분석 기준 모델들 (군집분석 제외)
- 보통 현업에서는 앙상블모델의 랜덤포레스트부터 모델을 훈련시킴
-   앙상블 모델으로만 확인 후 비교 선장히는 추세
- 회귀분석 모델
    - 선형회귀모델(선형회귀모델, 다항회귀모델, 하중회귀모델)
    - 릿지, 라쏘
    - 의사결정나무(트리모델), 로지스틱레그레이션모델
    - 앙상블모델(랜덤포레스트, 그레디언트부스트, 히스토그램그래디언트부스트, 엑스트라트리, 엑스지부스트 등등.. )

- 분류분석 모델
    - 의사결정나무(트리모델)
    - 앙상블모델(랜덤포레스트, 그레디언트부스트, 히스토그램그래디언트부스트, 엑스트라트리, 엑스지부스트 등등.. )
<br>

##### 선형회귀모델(Linear Regression Model)
- 특징
    - 가장 널리 사용되었던 대표 모델(현재도 일부 현업에서 선호)
    - 비교적 간단하며 성능이 뛰어남 회귀모델 수행 시 가장 처음에 비교모델로 사용되기도 함
    - 선형 회귀모델 : 일반적으로 직선을 의미(곡선은 다향회귀모델이라 칭함)
    - (직선) 선형회귀모델 : 독립변수(특성)이  한개인 경우 사용(일반적으로 선형 회귀모델이라 칭함)
    - (곡선) 선형 회귀모델 : 독립변수(특성)이 두개인 경우 사용(다항회귀모델)
    - (자유곡선) 선형 회귀모델 : 독립변수(특성)이 세개이상인 경우 사용(다중회귀모델)
    - 선형회귀모델의 라이브러리는 1개만 사용되며 선형/다항/다중은 모델이 판단함
        - 데이터를 넣어주기만 하면 됨

- 사용 라이브러리 : sklearn.linear_model
- 모델(클래스) : LinearRegression(회귀모델 공통 사용)

- 훈련 절차
    - 데이터 수집 > 데이터 전처리(차원처리, 분리, 스케일링) 
    -> 데이터 가공(특성이 추가될 경우 추가) > 훈련모델 생성 > 훈련 시키기
    -> 훈련 & 테스트 정확도(결정계수) 확인 > 과적합여부 확인 > 튜닝이 필요한 경우 튜닝
    -> 예측 > 예측 결과로 평가 > 최종 해석

```py
# 선형회귀모델 라이브러리 정의
from sklearn.linear_model import LinearRegression

### 1. 선형회귀 모델 생성
lr = LinearRegression()

### 2. 모델 훈련
lr.fit(train_input, train_target)

### 3. 훈련 및 테스트 독립변수로 정확도(결정계수) 확인
train_score = lr.score(train_input, train_target)
test_score = lr.score(test_input, test_target)

### 4. 과적합여부 해석
print(f"훈련 결정계수 : {train_score}, 테스트 결정계수 : {test_score}, 훈련 - 테스트 : {train_score - test_score}")

### 결과
# 훈련 결정계수 : 0.939846333997604, 테스트 결정계수 : 0.8247503123313558, 훈련 - 테스트 : 0.11509602166624822
# 훈련 정확도는 테스트 정확도에 비하여 다소 높음
# 과대적합이 발생하고 있는 것으로 판단됨

### 임의 길이 50cm 로 예측하기
# - 변수명 : pred
pred = lr.predict([[50]])

### 선형모델이 찾아낸 기울기와 절편 확인하기
# - 기울기
a = lr.coef_

# - y 절편
b = lr.intercept_

# 결과
# 기울기 : a = [39.01714496]
# y 절편 : b = -709.0186449535477

### 훈련 독립변수 및 종속변수로 산점도 그리기
# - 임의 데이터 길이 및 예측 무게로 산점도 그리기
```
<br>

![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_회귀분석선형회귀모델.png)
<br>

##### (곡선) 다항 회귀모델로 적용하기

- 다항회귀모델
    - 다항식을 사용하는 선형모델
    - 산점도의 형태가 곡선을 띄는 경우에 사용
    - 다항식(y) = ax^2 +bx + c
    - (a와 b는 기울기, c는 y절편), 다항회귀모델에서는 a, b를 계수라고 칭함
    - 기존 특성 1개의 값을 제곱한 값이 추가로 필요함 (특성 2개 사용)
```py
## 앞 과정은 동일함

### 임의 데이터 길이 50cm로 예측
pred = lr.predict([[50**2, 50]])

### 추세선을 그리기 위해 모델이 알아낸 기울기와 절편 확인
# - 기울기
coef = lr.coef_
a = coef[0]
b = coef[1]

# - y 절편
c = lr.intercept_

### 모델이 추출한 y절편 값까지 추세선 그리기
# - 곡선의 방정식에 따라 추세선은 곡선으로 그려야 함
```
![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_회귀분석다중선형회귀모델.png)

- [회귀분석_선형회귀분석모델_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day03/02_회귀분석_선형회귀모델.ipynb)
<br><br>



### DAY04
- 다중회귀모델(Multiple Regression)
    - 여러 개의 특성(항목, 컬럼, 퓨처 같은 용어)를 사용한 회귀모델
    - 특성이 많을수록 모델이 훈련(학습) 중에 직중력(복잡도)이 높아짐
    - 단점 : 훈련시간이 다소 오래 걸릴 수 있음 (시스템 성능에 따라 훈련 소요 시간이 달라짐)
    - 장점 : 기존 선형(직선 & 곡선) 모델이 비하여 과적합 해소에 도움이 되는 모델
<br>

- 성능을 높이는 방법
    - 데이터 양 늘리기(데이터 추가수집)
        - 데이터 양은 행단위 또는 열단위로 늘리는 것을 의미
    - 하이퍼 파라미터 튜닝
    - 새로운 모델 찾기
<br>

##### 특성 늘리기
- 특성 공학 적용
    - 열단위 특성 늘리기
    - 기존의 정확도(결정계수)를 더 높일 수 있는지 확인하는 절차
    - 특성은 임의 데이터를 사용하는 것이 아닌, 기존의 수집되어 있는 특성을 이용
<br>

- 특성을 생성하는 라이브러리
    - 패키지 : sklearn.preprocessing
    - 사용 라이브러리(클래스) : PolynomialFeatures()
        - 변환기 모델이라고 칭함
        - 실제 훈련 모델은 아님, 전처리 모델
        - *새로 생성할 특성들의 패턴을 찾음*
    - 사용되는 함수
        - fit() : 변환기 모델을 이용하여 생성할 특성 패턴 찾기
        - transform() : 찾은 패턴을 기준으로 특성 생성하기
<br>

- 특성 생성 순서 : 훈련모델 처리와 동일
    - 1. 변환기 모델 생성
    - 2. 변환기 모델 패턴 찾기 : fit(훈련 독립변수)
    - 3. 찾은 패턴으로 특성 생성 : transform(훈련/검증/테스트 독립변수)
<br>

- 특성 생성시 사용하는 데이터
    - fit()을 이용하여 패턴을 찾을 때는 "훈련 독립변수" 만 사용함
    - transform()을 이용하여 찾은 패턴으로 특성을 생성할 때
        - 훈련, 검증, 테스트 데이터 모두 처리 진행
    - 종속 변수는 원본 유지함(처리 대상이 아님, 정답이기 때문에)
<br>

##### 모델의 성능을 높이는 방법
- 1 데이터 증강(수집)
    - 전처리(특성 늘이기)
- 2 전처리(스케일링)
- 3 하이퍼 파라미터 튜닝
- 4 다른 모델 사용
<br>

##### 데이터 스케일링 - 전처리
- 특성들간의 단위(cm, g, kg, 등등) 차이로 인한 값의 범위가 크게 차이나는 경우에 사용
- 라이브러리를 이용해서 스케일링 처리 진행
- 보통 스케일링 대신 "정규화" 또는 "표준화" 라는 용어 사용
- 라이브러리
    - 패키지 : sklearn.preprocessing
    - 변환기 클래스 : StandardScaler, MinMaxScaler, RobustScaler
    - 사용함수 : fit(훈련 독립변수), transform(훈련, 검증, 테스트 독립변수)
- 변환기 클래스 특성
    - StandardScaler : 주로 분류에 사용되며 회귀에서도 자주 사용
    - MinMaxScaler : 회귀에서 주로 사용
    - RobustScaler : 회귀 또는 분류에서 모두 사용 가능 (많이 사용되지는 않음)
    - *** 모델 성능을 확인하기 위해서는 위 3개 각각에 대하여 모두 훈련 후 성능 검증 비교
<br>

- 한개 모델(클래스)로 성능 확인하는 방법
    - 1 순수한(아무것도 처리하지 않은) 원본 데이터(훈련, 검증, 테스트)로 훈련 및 성능 확인
    - 2 1번 항목 + 특성 추가 한 데이터로 훈련 및 성능 확인
    - 3 1번 항목 + 스케일링 한 데이터로 훈련 및 성능 확인
    - 4 1번 항목 + 특성 추가 + 스케일링 한 데이터로 훈련 및 성능 확인
    - 5 1번 항목 + 2번 항목 + 하이퍼 파라미터 튜닝한 데이터로 훈련 및 성능 확인
    - 6 1번 항목 + 3번 항목 + 하이퍼 파라미터 튜닝한 데이터로 훈련 및 성능 확인
    - 7 1번 항목 + 4번 항목 + 하이퍼 파라미터 튜닝한 데이터로 훈련 및 성능 확인

- [회귀분석_다중회귀모델](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day04/01_회귀분석_다중회귀모델.ipynb)
- [회귀분석_다중회귀모델_클래스예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day04/02_클래스생성_Model_Util.ipynb)
<br><br>



### DAY05 0305
##### 릿지(Ridge) 및 라쏘(Lasso) 모델 사용하기
- 릿지 및 라쏘 모델 특징
    - 과대 및 과소 적합을 조절하는 모델
    - 조절하기 위한 하이퍼 파라미터를 제공하고 있음
    - 하이퍼 파라미터 : 복작도를 조절할 수 있는 파라미터 값을 변경하여 과적합 조정
    - 릿지 및 라쏘에서는 "복잡도"라는 용어를 "규제"라는 용어로 사용함
    - 훈련 정확도는 다소 낮아지는 특징을 가지고 있음
    - 테스트 정확도는 높아지는 경향을 보이는 특징을 가지고 있음
    - 일반화에 최적화된 모델
    - 선형회귀모델 이후 향상된 모델로 많이 사용되고 있는 모델임

- 사용 방법
    - 사용 패티지 : sklearn.linear_model
    - 사용 모델(클래스) : Ridge, Lasso
    - 사용 함수 : 훈련(fit) 및 예측(predict) 등 기존과 동일한 함수 사용
<br>

##### 릿지(Ridge) 및 라쏘(Lasso) 모델 하이퍼 파라미터 튜닝
- 규제 - 하이퍼 파라미터
    - 모델 성능(정확도 및 과적합여부)에 영향을 미치는 파라미터
    - 규제 = 규제강도 = 강도 = 복잡도 모두 같은 의미
    - 규제 하이퍼 파라미터 이름 : alpha
    - 규제 값의 범위 : 0.001 ~ 100 사이의 값 중에 1개 사용
    - 규제 기본값 (default) : 1(생략가능)

- 규제 값의 성격
    - alpha 값이 작을 수록 훈련 정확도는 낮아지는 특징이 있음, 과대적합 모델에 적합
    - alpha 값이 높을 수록 훈련 정확도는 높아지는 특징이 있음, 과소적합 모델에 적합
    - 실제 값이 작고 높음에 따라서 확인을 해봐야 정확함
<br>

##### 데이터 특성들 간의 관계 확인
- 특성들 간의 관계 확인하기
    - 상관관계 분석 : 선형 또는 비선형 확인
    - 상관관계는 표 또는 시각적으로 확인
    - 시각화의 경우 산점행렬도(산점도 그래프)를 사용
    - 확인 방법 : 종속변수를 기준으로 다른 특성들간의 관계를 확인하면 됨
    - 선형인 경우 : 회귀분석 진행
    - 비선형인 경우 : 분류분석 진행

- 상관관계에서 사용하는 용어
    - 표 : 상관관계표
    - 시각화 그래프 : 산점행렬도
    - 상관관계를 나타내는 값 : 상관계수

- 사용하는 함수
    - corr() : 상관관계 표 형태로 데이터를 제공해주는 함수

- [릿지 및 라쏘 실습 예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day05/01_회귀분석_릿지_라쏘.ipynb)
<br>

##### 피어슨, 스피어만 상관관계 검증
- 상관관계 검증(검정) 방법
    - 1. 스피어만(Spearman) 상관관계 검정
        - 선형 또는 비선형 관계를 모두 포함하여 검정 가능
        - 보통 순위 형태의 데이터 특성(종속변수와 독립변수 각각) 간의 관계 확인에 사용
        - 예시 : 시험성적과 학업 성취도 간의 관계인 경우
                (시험 성적이 높을수록, 학업 성취도도 높아질까?)

    - 2. 피어슨(Pearson) 상관관계 검정
        - 선형 형태를 띄는 경우에 주로 사용되는 방법(비선형에서도 사용되기는 함)
        - 일반적으로 주로 사용되는 방법임
        - 보통 양적 크기 형태의 데이터 특성(종속변수와 독립변수 각각) 간의 관계 확인에 사용
        - 예시 : 온도와 아이스크림 판매량 간의 관계인 경우
            (날씨가 더우면, 아이스크림 판매량이 증가할까?)
<br>

- 상관관계 검증(검정)
    - 상관관계 검증은 종속변수와 독립변수 각각 간에 "유의미성"이 있는지 확인하는 절차임
    - 통계적 기법(통계학 이론)으로 사용된다.
        - 유의미성을 나타내는 이름: p-value
        - p-value의 값을 : "유의미 계수"라고 칭함
<br>

- 유의미 계수(p-value) 기준 해석(통상적인 통계학 기준으로 작성)
    - 1 p-value < 0.05 인경우
        - "유의미 함" 이라고 해석
        - 기무가설 기각, 대립가설을 채택하는 기준이 됨
        - 기무가설은 기존 이론, 대립가설은 새로운 이론
        - 새로운 이론, 즉 대립가설이 채택되어야만 연구진행이 가능함
    - 2 p-value >= 0.05인 경우
        - "유의미하지 않음" 이라고 해석
        - 기무가설 채택, 대립가설 기각의 기준이 됨
        - 새로운 이론으로 연구 진행 불가, 즉 주제 변경 또는 데이터 변경이 필요함을 의미함
    - 3 유의미성의 해석 방법(글쓰기 방법)
        - p-value < 0.05인 경우 글 작성 방법
            - (잘못된 작성 예시) p-value의 값이 0.05보다 작기 때문에 유의미하다고 판단됨
            - (올바르게 작성된 예시) p-value < 0.05 이므로 유의미하다고 판단됨
    - 4 유의미한 값의 범위 기준
        - 통계학에서는 통상적으로 0.05를 기준으로 하지만(이론상)
        - 연구하고자하는 분야에서 기존 사용된 허용치가 있다면, 그 기준을 이용하여도 됨
        - 만약 기존 연구의 허용치가 없다면, 통상적으로 0.05를 사용하지만
        - 0.1~0.05 사이의 값도 사용되는 경우가 있음
        - p-value < 0.05를 달리 해석하면, 신뢰구간 95% 이내로 만족함이라고 해석하기도 함
- [상관관계 검증 예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day05/02_회귀분석_주택가격예측.ipynb)
<br><br>



### DAY06
##### 하이퍼 파라미터 튜닝
- 모델의 성능에 영향을 미치는 속성값, 즉 파라미터의 값을 사람이 관여하여 변경하는 것
- 사람의 개입이 필요한 부분임
- 일반적으로 최초 훈련시에는 기본값(defult)을 사용하여 훈련 진행
- "기본값을 이용한 훈련 평가결과"를 기준으로 성능이 안좋은 경우 추가적으로 진행하는 절차임
- 하이퍼 파라미터의 값을 수정할 때는 직접 수정하면서 가장 성능이 좋을 때의 값을 찾을 수도 있음
    - 자동으로 하이퍼 파라미터의 값을 찾아주는 라이브러리를 이용하는 경우가 많음
    - 라이브러리를 이용할 경우 : 하이퍼 파라미터에 사용할 값 한개가 아닌 값의 범위를 넣어서 사용
    - 하이퍼 파라미터 값의 범위를 정의할 때는 "리스트 타입"으로 정의
<br>

- 하이퍼 파라미터 라이브러리
    - 패키지 : sklearn.model_selection
    - 튜닝모델(클래스) : GridSearchCV()
<br>

- GridSearchCV()
    - 모델에 대한 하이퍼 파라미터의 속성 값들을 스스로 찾아서 훈련까지 수행함
    - 하이퍼 파라미터로 정의한 값의 범위 값들을 이용해서 스스로 훈련을 함
    - 값들마다 훈련 후 성능비교를 수행한 다음 가장 성능이 좋은 값을 찾음
    - 하이퍼 파라미터의 값들로 스스로 훈련 및 평가를 진행하기 때문에 "모델" 클래스라고 칭함
    - 완료된 최종 결과물은 가장 best한 모델을 반환 받아서 사용할 수 있음
    - best한 모델은 최적의 하이퍼 파라미터 값들이 설정되어 있는 모델이 됨
    - GridSearchCV는 내부적으로 교차검증(CV, Validation)을 수행함
<br>

- 교차검증(CV, Validation)
    - 데이터를 자체적으로 독립변수와 종속변수의 여러 그룹으로 분리 (Fold, 기본값 5개)하여 사용
    - 교차검증은 그룹으로 분리된 값들 중 독립변수와 종속변수의 값들을 교차하면서(섞으면서) 훈련과 검증을 진행
    - 하이퍼 파라미터의 범위 값들을 기준으로 각 훈련 결과를 비교하면서 검증하게 됨
    - 시간이 다소 소요 될 수 있음 (시스템 성능에 따라 처리 시간에 차이가 있음)
        - 가급적 시스템 자원(CPU core의 갯수)을 최대한 전체 사용해서 수행
<br>

- 모델 선정 기준
    - 객관적 선정 기준
        - 과소적합, 즉 훈련 - 검증이 마이너스(-) 인 경우 무조건 제외
        - 과대적합 훈련이 검증보다 0.1이상 차이나는 경우 -> 튜닝 대상
        - 과대적합 훈련이 1인 경우 -> 무조건 제외
        - 과대적합 검증이 1인 경우 -> 제외 보다는 체크 대상
    - 주관적 선정 기준(분석가의 객관적이면서도 주관적인 판단 기준을 의미)
        - 여러 모델 중에 1번에 대한 객관적 선정 기준을 통과한 모델들 중에서 최종 모델을 선정하게 됨
        - 비교할 모델들의 훈련 정확도 및 과적합 여부의 차이가 급격하게 나는 경우
            - 훈련정확도의 차이가 많고, 과적합여부의 차이가 없는 경우 : 훈련 정확도 기준으로 선정
            - 훈련정확도의 차이가 없고, 과적합여부의 차이가 많은 경우 : 과적합여부 기준으로 선정
        - 비교할 모델들의 훈련정확도 및 과적합여부의 차이가 거의 없는경우
            - 오차값(MEA, MSE)의 차이가 많이 나는 경우 : 오차값 기준으로 선정
            - 오차값의 차이가 많지 않은 경우 : 분석가 주관에 따름
                - 훈련 정확도를 중시할 경우 훈련 정확도가 높은 기준으로 선정
                - 일반화를 중시할 경우 과적합의 차이가 낮은 기준으로 선정
<br>

- [하이퍼 파라미터 튜닝 및 전체 모델 평가](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day06/01_회귀분석_주택가격예측.ipynb)
    - GridSearchCV 클래스를 이용하여 최적의 하이퍼 파라미터가 적용된 분석 모델을 선정함
    - 최종 선정 모델을 다른곳에 사용 할 수 있도록 file로 저장하는 과정 진행
<br><br>



### DAY07
- 지금까지 배운 모든 모델을 활용하여 데이터 전처리 부터 상관관계 검증 등 모든 사전처리 진행
- 특성 공학 및 스케일링 등 모든처리 적용
- 모델별로 성능 평가 및 해석
    - 성능 평가는 특성공학/스케일링/하이퍼 파라미터 적용전/후 모두 훈련 평가 후 분석
- [실습_회귀모델_만족도예측](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day07/01_실습_회귀모델_만족도예측.ipynb)
- [Model_Class.py](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day07/Model_Class.py)
    - 모델 클래스 별도 생성하여 활용하였음
<br><br>



### DAY08 분류분석 시작 0310


<br><br>



### DAY09 0311

<br><br>



### DAY10  0312

<br><br>



### DAY11  군집분석 시작 0313


<br><br>



### DAY12  군집분석 이미지 분류 0314
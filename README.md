# 2025-Machine-Learning
2025년 빅데이터 기반 AI 개발 전문가 과정 머신러닝 기본 학습 리포지토리
<br>



### DAY 01
- 머신러닝 맛보기 (K-최근접이웃 모델)
    - 머신러닝 최초 가장 기본으로 사용하기 좋음 (실전에는 사용안하는 추세, 너무 기본 모델)

- 기본 라이브러리 설치
 - plotly : 시각화
```
pip install ipython jupyter pandas xlrd seaborn pyarrow openpyxl selenium folium plotly

pip install matplotlib==3.8
pip install numpy==1.26
```

- 머신러닝 라이브러리 설치
```
pip install scikit-learn==1.5.0
pip install xgboost==2.0.2
```
- 라이브러리 정의
```py
from sklearn.neighbors import KNeighborsClassifier
```
- <산점도의 형태에 따라서 분석 방법 선택>
- 선형(직선 또는 곡선 포함) 형태인 경우
    - 일반적으로 회귀분석 방법을 사용(분류 분석도 가능)
    - 선형이면서 연속적 값을 예측하는 경우에는 --> 회귀분석 모델 사용
    - 선형이면서 판단을 하는 경우 -> 분류분석 모델 사용
    - 선형이면서 판단을 하는 경우에는 분류 기준이 되는 범주형 데이터가 포함되어 있어야 함
- 선형 형태가 아닌 경우
    - 분류 분석 방법 중 -> 분류분석 모델 또는 군집분석 모델을 사용
<br>

- <분석 방법>
- 1. 회귀분석
    - 지도학습 회귀분석모델 사용 : 정답을 알고 있는 경우 사용
    - 정답의 형태 : 연속형 데이터
    - 예측의 의미 : 정답을 예측하는 것으로, 연속형 데이터를 추정하는 것
- 2. 분류분석
    - 2-1. 분류분석
        - 지도학습 분류분석모델 사용 : 정답을 알고 있는 경우 사용
        - 정답의 형태 : 범주형 데이터
        - 판단(분류)의 의미 : 정답을 판단하는 것으로 범주형 데이터를 분류하는 것
    - 2-1. 군집분석
        - 비지도 학습 군집분석모델 사용 : 정답을 모르는 상태에서 사용
        - 군집의 의미 : 데이터의 임의 특성을 기준으로 군집(클러스트, 그룹)을 만드는 것
            - 어느 그룹에 속하는지를 판단하는 것 (범주형 데이터를 분류하는 의미)
<br>

- 분류를 위한 데이터 전처리 및 가공
- 1. 데이터 특성에 맞게 합치기
    - 훈련(학습)을 시키기 위한 데이터 형태로 만들기
        - 문제 데이터 : [ [길이, 무게], [길이, 무게] ... ]
            - 문제 데이터를 [독립변수, X] 라고 칭함
            - 독립변수(x)는 2차원 형태를 갖추어야 함
            - 머신러닝 필수사항

        - 정답 데이터 : [ 도미, 도미, 도미, .... 빙어, 빙어 ... ]
            - 정답 데이터를 [종속변수, y] 라고 칭함
            - 종속변수(y)는 1차원 형태를 갖추어야 함
            - 머신러닝 & 딥러닝 필수사항
            - 분류 기준에서의 종속변수 형태
                - 둘중 하나를 분류할 때 > "이진분류" 0 또는 1중에 분류
                - 세개 이상 중에 하나를 분류할 때 > "다중분류" 0, 1, 2 ... n 중에 분류

    - 훈련(학습)에 사용되는 모든 특성의 데이터는 숫자값을 사용
        - 범주형 데이터가 문자인 경우에는 숫자(0~n까지)로 사용
        - 이때 원-핫인코딩을 이용하는 경우도 있음
        - 주로 직접 숫자로 변환하는 코드를 작성하여 변환

    - 분석 용어
        - 각 데이터(도미, 빙어)를 "특성" 이라고 칭함
        - 특성 => 컬럼, 항목, 퓨처(딥러닝), ... 모두 같은 의미
<br>

- 훈련(학습) 시키기
- 훈련에 사용할 훈련(학습) 모델
    - 모델 라이브러리 : KNeighborsClassifier
    - 모델 패키지 : sklearn.neighbors
    - 모델 이름 : KNN (K-Nearest Neighbors : K-최근접 이웃 "알고리즘"을 사용하는 "모델")
    - KNN은 머신러닝 모델 중에 가장 간단한 모델
    - 타 모델들과 비교용으로 주로 사용됨
<br>

- 처리 방식
    - 분류(판단, 예측) 하고자 하는 특성값들과 가장 가까운 이웃의 값들과 거리 비교
    - 가장 가까운 곳의 갯수(이웃들의 갯수)를 기준으로 비율(확률) 대비 판단
    - 비율이 가장 높은 쪽으로 판단 (다수결의 원칙을 따름)
<br>

- 훈련(학습) 순서
    - 1. 데이터 수집
    - 2. 데이터 전처라
    - 3. 데이터 가공
        - 독립변수, 종속변수 생성
        - 훈련 데이터, 테스트 데이터로 분류 또는 훈련, 검증, 테스트 데이터로 분류
    - 4. 훈련모델 생성
    - 5. 훈련 시키기
        - 훈련 데이터 사용
    - 6. 훈련모델 정확도 검증
        - 테스트 데이터 사용 또는 검증 데이터 사용
        - 훈련 정확도 및 테스트(검증) 정확도 확인 후 비교
        - 6-1. 튜닝
        - 6-2. 성능평가
    - 7. 예측하기(임의 데이터로 정답 잘 맞추는지 검증)
        - 임의 데이터, 즉 테스트 데이터를 의미
        - 7-1. 최종 정확도 검증(테스트 정확도 검증)
        - 7-2. 성능평가
<br>

- 하이퍼 파라미터 사용하기
    - 하이퍼 파라미터 의미
        - 사람이 직접 성능을 높이기 위해 특정 파라미터의 값을 수정해 주어야하는 것을 의미
        - 훈련 모델의 성능(정확도)에 영향을 미치는 파라미터를 "하이퍼 파라미터"라고 칭함
        - 하이퍼 파라미터의 값을 변경(튜닝)하면서 성능을 향상 시킬 수 있음

    - 하이퍼 파라미터 튜닝
        - 성능을 높이기 위해 파라미터의 값을 바꿔가면서 훈련검증을 하는 방식을 의미

    - KNN 에서 사용하는 하이퍼 파라미터
        - n_neighbors : 이웃의 갯수를 변경하면서 성능을 개선할 수 있음 (기본값 = 5)
        - 모델 생성시에 속성으로 넣어줌
        
- [K-최근접이웃 예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day01/01_K-최근접이웃_모델_생선구분.ipynb)
<br><br>



### DAY02

- 데이터 분리 : 훈련, 테스트 (또는 훈련, 검증, 테스트)

- 데이터 분리
    - 훈련 데이터 : fit()
    - 검증 데이터 : score()
    - 테스트 데이터 : predict()
    - 훈련과 테스트 데이터로만 분리한 경우에는 테스트 데이터로 score() 및 predict() 모두 사용
<br>

- 데이터를 분리하는 이유
    - 훈련이 잘 되었는지에 대한 모델의 성능 검증을 위함
    - 검증에 타당성을 입증하기 위함
<br>

- 분리기준
    - 2개로 분리 -> 훈련 : 테스트
    - 3개로 분리 -> 훈련 : 검증 : 테스트
<br>

- 분리 비율
    - 2개로 분리
        - 훈련(7) : 테스트(3) : 주로 사용 됨
        - 훈련(7.5) : 테스트 (2.5)
        - 훈련(6) : 테스트(4)
    - 3개로 분리
        - 훈련(6) : 검증(2) : 테스트(2) : 주로 사용 됨
        - 훈련(7) : 검증(1.5) : 테스트(1.5)
        - 훈련(7) : 검증(2) : 테스트(1)
<br>

- 주로 사용되는 변수 이름
    - 훈련 데이터(train)
        - 훈련 독립변수명 : train_input, train_X, train_data
        - 훈련 종속변수명 : train_target, train_y
    - 검증 데이터(val)
        - 훈련 독립변수명 : val_input, val_X, val_data
        - 훈련 종속변수명 : val_target, val_y
    - 테스트 데이터(test)
        - 훈련 독립변수명 : test_input, test_X, test_data
        - 훈련 종속변수명 : test_target, test_y
<br>

- 편향 해소 방법
    - 데이터의 특정 값들이 골고루 잘 섞이게 하면 됨
    - 데이터 전처리 및 가공 단계에서 처리
    - 섞는다는 의미 "split" 이라고 함
    <br>
    ```py
    plt.title("훈련도 데이터와 산점도 데이터 시각화")
    plt.scatter(train_input[ : ,0], train_input[: , 1], color="yellowgreen", label ="훈련 데이터")
    plt.scatter(test_input[ : ,0], test_input[ : ,1], color="skyblue", label ="테스트 데이터")
    plt.xlabel("length")
    plt.ylabel("weight")
    plt.legend()
    plt.grid()
    plt.show()
    ```
    <br>
    ![편향해소데이터섞기](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d01_편향해소랜덤섞기.png)

    - [KNN_훈련_및_테스트_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/01_KNN_훈련_및_테스트_데이터구성하기.ipynb)

    - [KNN_자동분류섞기_및_정규화_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/02_KNN_자동분류섞기_및_정규화.ipynb)
<br>

- KNN 회귀 모델
- 회귀모델의 결정계수(정확도)
    - 회귀모델에서는 정확도라고 표현하지 않으며, "결정계수"라고 함
    - 결정계수의 다른 표현 : 결정력, 설명력 이라고 함
    - 결정계수 값의 범위 : 0 ~ 1 사이의 값 (1에 가까울 수록 좋음)
    - 결과 문서 작성시 
        - "훈련의 결정계수가 0.97로 설명력이 매우 좋은 모델로 판단됨" 이라고 작성함
- 모델이 좋다 나쁘다의 판단 기준 값으로 사용
- +- 0.03 정도의 오차가 있는 모델이라고 표현
- [KNN_회귀모델_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day02/03_KNN_회귀모델.ipynb)
<br><br>



### DAY03

- 정확도를 이용하여 모델 성능 평가하기 : 과적합여부 판정
<br>

- 회귀분석 및 분류분석 모두 공통 적용되는 사항
    - 훈련 이후 훈련 데이터를 이용한 정확도(socre)와 검증(테스트) 데이터를 이용한 정확도(score) 비교
    - 비교한 결과를 기준으로 많은 차이가 나는 경우 -> "과적합이 발생한다" 라고 함
    - 과적합 용어 : 과대적합, 과소적합, 일반화
    - 과적합의 기준 : 정확한 정답은 없음(보통 0.1 차이가 나면 과적합이 발생한 것으로 봄)
<br>

##### 과적합 분류
- 과대적합
    - 훈련 정확도 > 검증 (또는 테스트) 정확도인 경우
    - 훈련 정확도가 1이 나온 경우 : 모델 사용 불가
    - 훈련 정확도와 검증(또는 테스트) 정확도가 0.1 이상 차이가 나는 경우
    - 과대적합 처리 방법
        - 1. 데이터 양 늘리기 (데이터 추가 수집 필요) -> 데이터 수집에 어려움이 있음
        - 2. 하이퍼 파라미터 튜닝 -> 일반적으로 선행해서 처리 시작
        - 3. 다른 모델 찾기 -> 1, 2 번으로 처리가 안될 경우 사용
    - 과소적합
        - 훈련 정확도 < 검증 (또는 테스트) 정확도인 경우
        - 훈련 모델 사용 불가
        - 과소적합 처리 방법
            - 1. 데이터 양 늘리기 (데이터 추가 수집 필요) -> 데이터 수집에 어려움이 있음
            - 2. 하이퍼 파라미터 튜닝 -> 일반적으로 선행해서 처리 시작
            - 3. 다른 모델 찾기 -> 1, 2 번으로 처리가 안될 경우 사용
    - 일반화
        - 훈련 정확도와 검증 (또는 테스트) 정확도 차이가 0.01 ~ 0.09 이내인 경우
<br>

- 문서에 표현하는 용어
    - 일반화가 되었다는 가정하에 주로 사용
    - 훈련 정확도(score) 0.95 이상 : 매우 훌륭한 모델
    - 훈련 정확도(score) 0.90 이상 : 훌륭한 모델
    - 훈련 정확도(score) 0.85 이상 : 좋은 모델
    - 훈련 정확도(score) 0.85 미만 : 좋다라는 표현은 사용하지 않음

- 가장 이상적인 정확도(score) 비교
    - 훈련 정확도 > 검증 정확도 > 테스트 정확도 : 가장 이상적
    - 훈련정확도 > 검증 정확도 < 테스트 정확도 : 이렇게 나오는 경우도 인정

- 가장 이상적인 정확도를 만들기 위한 작업들
    - 전처리 : 편향 처리, 적절한 데이터 분리, 스케일링
    - 하이퍼 파라미터 튜닝 : 모델마다 가지고 있는 성능에 영향을 미치는 파라미터 값 수정
    - 데이터 수집 : 양적 수집
<br>

##### 하이퍼 파라미터 튜닝
- 모델마다 튜닝할 파라미터는 각기 다름
- KNN 에서 기본적으로 튜닝할 파라미터 : 이웃의 갯수
- 튜닝방법
    1. 훈련모델 생성
     2. 최초 훈련 시키기
     3. 하이퍼 파라미터 값 변경 > 훈련 시키기
     4. 정확도 확인
     5. 3번 ~ 4번 반복

- 이웃의 갯수 3 ~ 훈련 데이터의 갯수만큼 훈련 시킨 결과
    - 훈련 정확도와 테스트 정확도를 선그래프 시각적으로 확인
    - x축 : 이웃의 갯수, y축 : 훈련 및 테스트 정확도
    - 훈련 정확도 선과 테스트 정확도 선을 하나의 그래프에 그려서 비교
    <br>
    ![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_이웃갯수에따른데이터정확도비교.png)

##### 최종 평가하기

- 회귀분석 평가
    - 평가를 위해서는 예측(predict)이 선행 되어야 함
    - 예측된 결과를 기준으로 평가를 수행

- 회귀분석 평가 방법
    - 평균절대오차(MAE, Mean Absolute Error)
    - 평균제곱오차(MSE, Mean Squere Error)
    - 결정계수(R2-score) == score()와 동일

- 평과 결과 해석
    - 평균절대오차(MAE)의 결과를 이용해서 오차의 범위 확인 가능
    - 결정계수(R2) 값을 이용하여 모델 선정여부 판정
        - 여러 모델들간에 비교하여 최종 선정 시에 R2-score의 값을 기준으로 선정여부 판정
        - 여러 모델 선정 기준 : R2-score 값이 높고 훈련 정확도가 높은 모델 선정
<br>

##### KNN 모델의 한계를 극복한 모델들 (회귀 및 분류 공통)
- ** 지도학습 기반에서 회귀 및 분류분석 기준 모델들 (군집분석 제외)
- 보통 현업에서는 앙상블모델의 랜덤포레스트부터 모델을 훈련시킴
-   앙상블 모델으로만 확인 후 비교 선장히는 추세
- 회귀분석 모델
    - 선형회귀모델(선형회귀모델, 다항회귀모델, 하중회귀모델)
    - 릿지, 라쏘
    - 의사결정나무(트리모델), 로지스틱레그레이션모델
    - 앙상블모델(랜덤포레스트, 그레디언트부스트, 히스토그램그래디언트부스트, 엑스트라트리, 엑스지부스트 등등.. )

- 분류분석 모델
    - 의사결정나무(트리모델)
    - 앙상블모델(랜덤포레스트, 그레디언트부스트, 히스토그램그래디언트부스트, 엑스트라트리, 엑스지부스트 등등.. )
<br>

##### 선형회귀모델(Linear Regression Model)
- 특징
    - 가장 널리 사용되었던 대표 모델(현재도 일부 현업에서 선호)
    - 비교적 간단하며 성능이 뛰어남 회귀모델 수행 시 가장 처음에 비교모델로 사용되기도 함
    - 선형 회귀모델 : 일반적으로 직선을 의미(곡선은 다향회귀모델이라 칭함)
    - (직선) 선형회귀모델 : 독립변수(특성)이  한개인 경우 사용(일반적으로 선형 회귀모델이라 칭함)
    - (곡선) 선형 회귀모델 : 독립변수(특성)이 두개인 경우 사용(다항회귀모델)
    - (자유곡선) 선형 회귀모델 : 독립변수(특성)이 세개이상인 경우 사용(다중회귀모델)
    - 선형회귀모델의 라이브러리는 1개만 사용되며 선형/다항/다중은 모델이 판단함
        - 데이터를 넣어주기만 하면 됨

- 사용 라이브러리 : sklearn.linear_model
- 모델(클래스) : LinearRegression(회귀모델 공통 사용)

- 훈련 절차
    - 데이터 수집 > 데이터 전처리(차원처리, 분리, 스케일링) 
    -> 데이터 가공(특성이 추가될 경우 추가) > 훈련모델 생성 > 훈련 시키기
    -> 훈련 & 테스트 정확도(결정계수) 확인 > 과적합여부 확인 > 튜닝이 필요한 경우 튜닝
    -> 예측 > 예측 결과로 평가 > 최종 해석

```py
# 선형회귀모델 라이브러리 정의
from sklearn.linear_model import LinearRegression

### 1. 선형회귀 모델 생성
lr = LinearRegression()

### 2. 모델 훈련
lr.fit(train_input, train_target)

### 3. 훈련 및 테스트 독립변수로 정확도(결정계수) 확인
train_score = lr.score(train_input, train_target)
test_score = lr.score(test_input, test_target)

### 4. 과적합여부 해석
print(f"훈련 결정계수 : {train_score}, 테스트 결정계수 : {test_score}, 훈련 - 테스트 : {train_score - test_score}")

### 결과
# 훈련 결정계수 : 0.939846333997604, 테스트 결정계수 : 0.8247503123313558, 훈련 - 테스트 : 0.11509602166624822
# 훈련 정확도는 테스트 정확도에 비하여 다소 높음
# 과대적합이 발생하고 있는 것으로 판단됨

### 임의 길이 50cm 로 예측하기
# - 변수명 : pred
pred = lr.predict([[50]])

### 선형모델이 찾아낸 기울기와 절편 확인하기
# - 기울기
a = lr.coef_

# - y 절편
b = lr.intercept_

# 결과
# 기울기 : a = [39.01714496]
# y 절편 : b = -709.0186449535477

### 훈련 독립변수 및 종속변수로 산점도 그리기
# - 임의 데이터 길이 및 예측 무게로 산점도 그리기
```
<br>

![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_회귀분석선형회귀모델.png)
<br>

##### (곡선) 다항 회귀모델로 적용하기

- 다항회귀모델
    - 다항식을 사용하는 선형모델
    - 산점도의 형태가 곡선을 띄는 경우에 사용
    - 다항식(y) = ax^2 +bx + c
    - (a와 b는 기울기, c는 y절편), 다항회귀모델에서는 a, b를 계수라고 칭함
    - 기존 특성 1개의 값을 제곱한 값이 추가로 필요함 (특성 2개 사용)
```py
## 앞 과정은 동일함

### 임의 데이터 길이 50cm로 예측
pred = lr.predict([[50**2, 50]])

### 추세선을 그리기 위해 모델이 알아낸 기울기와 절편 확인
# - 기울기
coef = lr.coef_
a = coef[0]
b = coef[1]

# - y 절편
c = lr.intercept_

### 모델이 추출한 y절편 값까지 추세선 그리기
# - 곡선의 방정식에 따라 추세선은 곡선으로 그려야 함
```
![테스트정확도비교](https://raw.githubusercontent.com/y7pWuXAq/2025-Machine-Learning/refs/heads/main/images/d03_회귀분석다중선형회귀모델.png)

- [회귀분석_선형회귀분석모델_예제](https://github.com/y7pWuXAq/2025-Machine-Learning/blob/main/day03/02_회귀분석_선형회귀모델.ipynb)